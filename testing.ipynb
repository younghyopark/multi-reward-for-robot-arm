{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b289df75-9ecf-48de-af51-5a16eaa8f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import register\n",
    "# from registration import registry, register, make, spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9080ccf-eeb8-4ea9-9034-00b37cb11801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import os, sys\n",
    "from arguments import get_args\n",
    "from mpi4py import MPI\n",
    "from rl_modules.ddpg_agent import ddpg_agent\n",
    "import random\n",
    "import torch\n",
    "\n",
    "\n",
    "# from robotics.pick_and_place import FetchPickAndPlaceEnv as MyFetchPickAndPlaceEnv\n",
    "# from robotics.push import FetchPushEnv as MyFetchPushEnv\n",
    "# from robotics.reach import FetchReachEnv as MyFetchReachEnv\n",
    "# from robotics.slide import FetchSlideEnv as MyFetchSlideEnv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a06df43a-5a81-4979-94b4-be9e611580de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env_params(env):\n",
    "    obs = env.reset()\n",
    "    # close the environment\n",
    "    params = {'obs': obs['observation'].shape[0],\n",
    "            'goal': obs['desired_goal'].shape[0],\n",
    "            'action': env.action_space.shape[0],\n",
    "            'action_max': env.action_space.high[0],\n",
    "              'num_reward':env.num_reward\n",
    "            }\n",
    "    params['max_timesteps'] = env._max_episode_steps\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "370fdd78-b2a3-4e46-a564-92fc6e02ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    env_name = 'FetchPickAndPlace-v1'\n",
    "    n_epochs = 50\n",
    "    n_cycles = 50\n",
    "    n_batches = 40\n",
    "    save_interval = 5\n",
    "    seed = 123\n",
    "    num_workers = 1\n",
    "    replay_strategy = 'future'\n",
    "    clip_return = 50.\n",
    "    save_dir = 'saved_models/'\n",
    "    noise_eps = 0.2\n",
    "    random_eps = 0.3\n",
    "    buffer_size = int(1e6)\n",
    "    replay_k = 4\n",
    "    clip_obs = float(200)\n",
    "    batch_size = 256\n",
    "    gamma = 0.98\n",
    "    action_l2 = 1.\n",
    "    lr_actor = 0.001\n",
    "    lr_critic = 0.001\n",
    "    polyak = 0.95\n",
    "    n_test_rollouts = 10\n",
    "    clip_range = 5.\n",
    "    demo_length = 20\n",
    "    cuda = False\n",
    "    num_rollouts_per_mpi = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f473df47-ecb5-4063-9d09-3bb1746fc95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/parallels/gym-multiRL/gym_multiRL/envs/assets/fetch/pick_and_place.xml\n",
      "my_fetch_env is loaded, not the original gym one\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('gym_multiRL:MultiRLFetchPickAndPlaceMulti-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d992bbe6-7583-4ce1-b112-64806b355016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multi'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7b37ef4-d5e9-43a1-93f9-ab35bc0351c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_params = get_env_params(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deba488f-b37c-4cfc-9a6b-aac34cfd9225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0., -0., -0., -0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.compute_reward(np.array([1,2,3]),np.array([1,2,3]),None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58a1606a-7f51-4c74-b254-97a2fab45ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_trainer = ddpg_agent(args,env,env_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f30f7ee7-15c3-43e9-9b9f-c85ff5fa2e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actor(\n",
       "  (fc1): Linear(in_features=28, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (action_out): Linear(in_features=256, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddpg_trainer.actor_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32236dc2-532c-4fe9-b06a-3c37edf57e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "critic(\n",
       "  (fc1): Linear(in_features=32, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (intermediate_q_out): Linear(in_features=256, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddpg_trainer.critic_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b13f8e55-8376-4b24-9394-58aecfd322bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation  = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d75f6351-cfd0-4db9-81f9-8836404325a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddpg_trainer.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2376e4d-ec1e-4f73-bdae-bb4067b374f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multi'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e43685d3-836d-4ac9-afae-d5823322c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def goal_distance(goal_a, goal_b):\n",
    "    assert goal_a.shape == goal_b.shape\n",
    "    return np.linalg.norm(goal_a - goal_b, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62bd5dc4-dab2-44d6-b520-97cb1a0bf96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'obs': 25, 'goal': 3, 'action': 4, 'action_max': 1.0, 'max_timesteps': 50}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_env_params(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c410fe45-0fec-49fc-ace3-150840e9f79f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b51ac876-9c14-461b-8b7f-59567eb21bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(50,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(50,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(50,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(50,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-74123eb7b0f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mddpg_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/RL_experiments/multi-reward-for-robot-arm/rl_modules/ddpg_agent.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0;31m# train the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                 \u001b[0;31m# soft update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_soft_update_target_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_target_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RL_experiments/multi-reward-for-robot-arm/rl_modules/ddpg_agent.py\u001b[0m in \u001b[0;36m_update_network\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mcritic_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0msync_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RL_experiments/multi-reward-for-robot-arm/mpi_utils/mpi_utils.py\u001b[0m in \u001b[0;36msync_grads\u001b[0;34m(network)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mglobal_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAllreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMPI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSUM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0m_set_flat_params_or_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'grads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# get the flat grads or params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RL_experiments/multi-reward-for-robot-arm/mpi_utils/mpi_utils.py\u001b[0m in \u001b[0;36m_set_flat_params_or_grads\u001b[0;34m(network, flat_params, mode)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpointer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpointer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mpointer\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ddpg_trainer.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e43ebc09-1da6-48c9-99ff-db64581d08a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.compute_reward(np.array([1,2,3]),np.array([1,2,3]),None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70d35b4e-58ca-405d-bc87-74ad13bed4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multi'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "973b26a1-cdac-45c2-ae11-5974c634a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39885374-e314-480b-9629-6706c2947b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/parallels/gym-multiRL/gym_multiRL/envs/assets/fetch/slide.xml\n",
      "my_fetch_env is loaded, not the original gym one\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('gym_multiRL:MultiRLFetchSlideMulti-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec842c3e-a741-413e-9dd6-3e9fb39b335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_env = gym.make('FetchSlide-v1')\n",
    "info = dict()\n",
    "info['velocity'] = np.array([1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5b75047-e5a9-4610-8680-1b761535a646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.23606798,  0.        , -1.        , -2.        ,  0.        ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.compute_reward(np.array([1,1,1]),np.array([1,2,3]),info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16d4947c-79a1-4467-8c46-1f0ff72fa5ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6ab0c5be5a1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgym_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/RL/lib/python3.7/site-packages/gym/core.py\u001b[0m in \u001b[0;36mcompute_reward\u001b[0;34m(self, achieved_goal, desired_goal, info)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0machieved_goal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_goal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0machieved_goal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_goal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/RL/lib/python3.7/site-packages/gym/envs/robotics/fetch_env.py\u001b[0m in \u001b[0;36mcompute_reward\u001b[0;34m(self, achieved_goal, goal, info)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0machieved_goal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Compute distance between goal and the achieved goal.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoal_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0machieved_goal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sparse'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/RL/lib/python3.7/site-packages/gym/envs/robotics/fetch_env.py\u001b[0m in \u001b[0;36mgoal_distance\u001b[0;34m(goal_a, goal_b)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgoal_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoal_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mgoal_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgoal_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoal_a\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgoal_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "gym_env.compute_reward(1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39711e7a-9196-42dc-8d76-a0af7438430a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.has_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d71315be-cfb5-4d10-9946-0aaa52ee12a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'observation': array([ 9.95644936e-01,  7.48909349e-01,  4.12685879e-01,  8.98325332e-01,\n",
       "         8.17837759e-01,  4.14022562e-01, -9.73196038e-02,  6.89284106e-02,\n",
       "         1.33668285e-03, -2.02409822e-06,  1.46269158e-03, -5.32964268e-03,\n",
       "         1.24548653e-04, -1.88202234e-02,  1.18415598e-03, -5.54487050e-05,\n",
       "         7.46713768e-05,  1.86450993e-02, -4.64845346e-04, -4.83036131e-03,\n",
       "        -1.22686993e-03,  5.01588816e-05, -2.30984296e-06,  4.63429471e-07,\n",
       "         5.47231104e-05]),\n",
       " 'achieved_goal': array([0.89832533, 0.81783776, 0.41402256]),\n",
       " 'desired_goal': array([1.64022055, 1.02262493, 0.41401894]),\n",
       " 'grip_pos': array([0.99564494, 0.74890935, 0.41268588]),\n",
       " 'grip_velp': array([-1.22686993e-03,  5.01588816e-05, -2.30984296e-06]),\n",
       " 'object_pos': array([0.89832533, 0.81783776, 0.41402256]),\n",
       " 'object_rot': array([-0.00532964,  0.00012455, -0.01882022]),\n",
       " 'object_velp': array([ 1.18415598e-03, -5.54487050e-05,  7.46713768e-05]),\n",
       " 'object_velr': array([ 0.0186451 , -0.00046485, -0.00483036]),\n",
       " 'gripper_state': array([-2.02409822e-06,  1.46269158e-03]),\n",
       " 'gripper_vel': array([4.63429471e-07, 5.47231104e-05])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8337b93d-efa4-4bd0-af96-5ea670d6562c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,1,1]).ndim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "862b93b3-9fd6-4408-8f73-0d694c43173b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(np.array([1,1,1]),axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ccca8963-c76b-4107-a9d2-67f85edec074",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((50,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "75985da0-8f73-4460-ade3-301999dc9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.zeros((50,1))\n",
    "z =np.zeros((50,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "278f489c-ec7a-4652-99e7-f7b55ccdd835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 3)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([x,y,z],1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2b52554b-867c-4d50-a6b2-44835de291ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-e0b9481fddfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0;36m3.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "(3.).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3247a457-29f1-4e49-b8e1-e0d8ddccbacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(x, np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2e4ca6a8-c8ce-4198-ba86-49a46fd6fa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.float64(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "87a3509e-4587-4fd7-9d6d-cbf465f92a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "efa110b7-30ca-4497-8feb-1b124f7963d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(np.array([x]),axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2be9db9e-64a2-4e11-b900-cb173326348e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fc247e-b48d-4c1e-adcf-207794b3aa08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
