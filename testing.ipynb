{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b289df75-9ecf-48de-af51-5a16eaa8f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import register\n",
    "from registration import registry, register, make, spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9080ccf-eeb8-4ea9-9034-00b37cb11801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import os, sys\n",
    "from arguments import get_args\n",
    "from mpi4py import MPI\n",
    "from rl_modules.ddpg_agent import ddpg_agent\n",
    "import random\n",
    "import torch\n",
    "\n",
    "\n",
    "from robotics.pick_and_place import FetchPickAndPlaceEnv as MyFetchPickAndPlaceEnv\n",
    "from robotics.push import FetchPushEnv as MyFetchPushEnv\n",
    "from robotics.reach import FetchReachEnv as MyFetchReachEnv\n",
    "from robotics.slide import FetchSlideEnv as MyFetchSlideEnv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a06df43a-5a81-4979-94b4-be9e611580de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env_params(env):\n",
    "    obs = env.reset()\n",
    "    # close the environment\n",
    "    params = {'obs': obs['observation'].shape[0],\n",
    "            'goal': obs['desired_goal'].shape[0],\n",
    "            'action': env.action_space.shape[0],\n",
    "            'action_max': env.action_space.high[0],\n",
    "            }\n",
    "    params['max_timesteps'] = env._max_episode_steps\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "370fdd78-b2a3-4e46-a564-92fc6e02ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    env_name = 'FetchPickAndPlace-v1'\n",
    "    n_epochs = 50\n",
    "    n_cycles = 50\n",
    "    n_batches = 40\n",
    "    save_interval = 5\n",
    "    seed = 123\n",
    "    num_workers = 1\n",
    "    replay_strategy = 'future'\n",
    "    clip_return = 50.\n",
    "    save_dir = 'saved_models/'\n",
    "    noise_eps = 0.2\n",
    "    random_eps = 0.3\n",
    "    buffer_size = int(1e6)\n",
    "    replay_k = 4\n",
    "    clip_obs = float(200)\n",
    "    batch_size = 256\n",
    "    gamma = 0.98\n",
    "    action_l2 = 1.\n",
    "    lr_actor = 0.001\n",
    "    lr_critic = 0.001\n",
    "    polyak = 0.95\n",
    "    n_test_rollouts = 10\n",
    "    clip_range = 5.\n",
    "    demo_length = 20\n",
    "    cuda = False\n",
    "    num_rollouts_per_mpi = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f473df47-ecb5-4063-9d09-3bb1746fc95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make('FetchPickAndPlaceMulti-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d992bbe6-7583-4ce1-b112-64806b355016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multi'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7b37ef4-d5e9-43a1-93f9-ab35bc0351c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_params = get_env_params(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deba488f-b37c-4cfc-9a6b-aac34cfd9225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.compute_reward(np.array([1,2,3]),np.array([1,2,3]),None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58a1606a-7f51-4c74-b254-97a2fab45ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_trainer = ddpg_agent(args,env,env_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f30f7ee7-15c3-43e9-9b9f-c85ff5fa2e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actor(\n",
       "  (fc1): Linear(in_features=28, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (action_out): Linear(in_features=256, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddpg_trainer.actor_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32236dc2-532c-4fe9-b06a-3c37edf57e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "critic(\n",
       "  (fc1): Linear(in_features=32, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (q_out): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddpg_trainer.critic_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b13f8e55-8376-4b24-9394-58aecfd322bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation  = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d75f6351-cfd0-4db9-81f9-8836404325a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddpg_trainer.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2376e4d-ec1e-4f73-bdae-bb4067b374f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multi'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e43685d3-836d-4ac9-afae-d5823322c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def goal_distance(goal_a, goal_b):\n",
    "    assert goal_a.shape == goal_b.shape\n",
    "    return np.linalg.norm(goal_a - goal_b, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62bd5dc4-dab2-44d6-b520-97cb1a0bf96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'obs': 25, 'goal': 3, 'action': 4, 'action_max': 1.0, 'max_timesteps': 50}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_env_params(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c410fe45-0fec-49fc-ace3-150840e9f79f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b51ac876-9c14-461b-8b7f-59567eb21bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(50,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(50,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(50,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(50,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-74123eb7b0f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mddpg_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/RL_experiments/multi-reward-for-robot-arm/rl_modules/ddpg_agent.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0;31m# train the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                 \u001b[0;31m# soft update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_soft_update_target_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_target_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RL_experiments/multi-reward-for-robot-arm/rl_modules/ddpg_agent.py\u001b[0m in \u001b[0;36m_update_network\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mcritic_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0msync_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RL_experiments/multi-reward-for-robot-arm/mpi_utils/mpi_utils.py\u001b[0m in \u001b[0;36msync_grads\u001b[0;34m(network)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mglobal_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAllreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMPI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSUM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0m_set_flat_params_or_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'grads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# get the flat grads or params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RL_experiments/multi-reward-for-robot-arm/mpi_utils/mpi_utils.py\u001b[0m in \u001b[0;36m_set_flat_params_or_grads\u001b[0;34m(network, flat_params, mode)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpointer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpointer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mpointer\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ddpg_trainer.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e43ebc09-1da6-48c9-99ff-db64581d08a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.compute_reward(np.array([1,2,3]),np.array([1,2,3]),None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70d35b4e-58ca-405d-bc87-74ad13bed4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multi'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "973b26a1-cdac-45c2-ae11-5974c634a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39885374-e314-480b-9629-6706c2947b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/parallels/RL_experiments/gym-multiRL/gym_multiRL/envs/assets/fetch/slide.xml\n",
      "my_fetch_env is loaded, not the original gym one\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('gym_multiRL:MultiRLFetchSlideMulti-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec842c3e-a741-413e-9dd6-3e9fb39b335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_env = gym.make('FetchSlide-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5b75047-e5a9-4610-8680-1b761535a646",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compute_reward() missing 2 required positional arguments: 'desired_goal' and 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-9557116a26a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0machieved_goal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: compute_reward() missing 2 required positional arguments: 'desired_goal' and 'info'"
     ]
    }
   ],
   "source": [
    "env.compute_reward(achieved_goal = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16d4947c-79a1-4467-8c46-1f0ff72fa5ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compute_reward() missing 3 required positional arguments: 'achieved_goal', 'desired_goal', and 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-06e6529b1c83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgym_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: compute_reward() missing 3 required positional arguments: 'achieved_goal', 'desired_goal', and 'info'"
     ]
    }
   ],
   "source": [
    "gym_env.compute_reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39711e7a-9196-42dc-8d76-a0af7438430a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.has_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d71315be-cfb5-4d10-9946-0aaa52ee12a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'observation': array([ 9.95644936e-01,  7.48909349e-01,  4.12685879e-01,  8.98325332e-01,\n",
       "         8.17837759e-01,  4.14022562e-01, -9.73196038e-02,  6.89284106e-02,\n",
       "         1.33668285e-03, -2.02409822e-06,  1.46269158e-03, -5.32964268e-03,\n",
       "         1.24548653e-04, -1.88202234e-02,  1.18415598e-03, -5.54487050e-05,\n",
       "         7.46713768e-05,  1.86450993e-02, -4.64845346e-04, -4.83036131e-03,\n",
       "        -1.22686993e-03,  5.01588816e-05, -2.30984296e-06,  4.63429471e-07,\n",
       "         5.47231104e-05]),\n",
       " 'achieved_goal': array([0.89832533, 0.81783776, 0.41402256]),\n",
       " 'desired_goal': array([1.64022055, 1.02262493, 0.41401894]),\n",
       " 'grip_pos': array([0.99564494, 0.74890935, 0.41268588]),\n",
       " 'grip_velp': array([-1.22686993e-03,  5.01588816e-05, -2.30984296e-06]),\n",
       " 'object_pos': array([0.89832533, 0.81783776, 0.41402256]),\n",
       " 'object_rot': array([-0.00532964,  0.00012455, -0.01882022]),\n",
       " 'object_velp': array([ 1.18415598e-03, -5.54487050e-05,  7.46713768e-05]),\n",
       " 'object_velr': array([ 0.0186451 , -0.00046485, -0.00483036]),\n",
       " 'gripper_state': array([-2.02409822e-06,  1.46269158e-03]),\n",
       " 'gripper_vel': array([4.63429471e-07, 5.47231104e-05])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8337b93d-efa4-4bd0-af96-5ea670d6562c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
